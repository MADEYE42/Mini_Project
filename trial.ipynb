{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Input and output folder paths\n",
    "input_folder = r'C:\\Users\\Vivek\\Downloads\\FETAL_PLANES_ZENODO\\Images'\n",
    "output_folder = r'C:\\Users\\Vivek\\Downloads\\FETAL_PLANES_ZENODO\\Images\\02.Enhancement and Segmentation'\n",
    "\n",
    "# Ensure the output folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "counter=0\n",
    "# Process each image in the input folder\n",
    "for filename in os.listdir(input_folder):\n",
    "    counter=counter+1\n",
    "    print(counter)\n",
    "    # Read the image as grayscale\n",
    "    img_path = os.path.join(input_folder, filename)\n",
    "    img = cv2.imread(img_path, 0)\n",
    "    # Add this check before processing the image\n",
    "    if not os.path.isfile(img_path):\n",
    "        print(f\"Error: Image file not found - {img_path}\")\n",
    "        continue  # Skip to the next iteration\n",
    "\n",
    "\n",
    "    # Apply histogram equalization to enhance contrast\n",
    "    equalized_img = cv2.equalizeHist(img)\n",
    "\n",
    "    # Apply median blur for noise reduction\n",
    "    median_blur = cv2.medianBlur(equalized_img, 5)\n",
    "\n",
    "    # Thresholding to create a binary mask of the cranium and brain\n",
    "    _, cranium_brain_mask = cv2.threshold(median_blur, 180, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Find contours in the mask\n",
    "    contours, _ = cv2.findContours(cranium_brain_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Find the contour with the largest area\n",
    "    max_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    # Create a blank mask image\n",
    "    mask_image = np.zeros_like(img)\n",
    "\n",
    "    # Draw the largest contour on the mask\n",
    "    cv2.drawContours(mask_image, [max_contour], -1, (255), thickness=cv2.FILLED)\n",
    "\n",
    "    # Create a circular mask centered at the image center\n",
    "    center_x = img.shape[1] // 2\n",
    "    center_y = img.shape[0] // 2\n",
    "    radius = int(min(img.shape) * 0.4)  # Adjust the radius as needed\n",
    "    cv2.circle(mask_image, (center_x, center_y), radius, (255), thickness=cv2.FILLED)\n",
    "\n",
    "    # Apply the mask to the original image\n",
    "    output_image = cv2.bitwise_and(img, mask_image)\n",
    "\n",
    "    # Find the bounding box of the largest contour\n",
    "    x, y, w, h = cv2.boundingRect(max_contour)\n",
    "\n",
    "    # Add padding to the bounding box\n",
    "    padding = 20  # Adjust the padding size as needed\n",
    "    x -= padding\n",
    "    y -= padding\n",
    "    w += 2 * padding\n",
    "    h += 2 * padding\n",
    "\n",
    "    # Ensure the bounding box is within the image boundaries\n",
    "    x = max(0, x)\n",
    "    y = max(0, y)\n",
    "    w = min(w, img.shape[1] - x)\n",
    "    h = min(h, img.shape[0] - y)\n",
    "\n",
    "    # Crop the output image to the bounding box region\n",
    "    output_image = output_image[y:y+h, x:x+w]\n",
    "\n",
    "    # Enhance the output image\n",
    "    enhanced_image = cv2.equalizeHist(output_image)\n",
    "\n",
    "    # Save the enhanced output image\n",
    "    output_path = os.path.join(output_folder, filename)\n",
    "    cv2.imwrite(output_path, enhanced_image)\n",
    "\n",
    "    \n",
    "\n",
    "print(\"Processing completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_name</th>\n",
       "      <th>Patient_num</th>\n",
       "      <th>Plane</th>\n",
       "      <th>Brain_plane</th>\n",
       "      <th>Train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Patient00001_Plane1_1_of_15</td>\n",
       "      <td>1</td>\n",
       "      <td>Other</td>\n",
       "      <td>Not A Brain</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Patient00001_Plane1_2_of_15</td>\n",
       "      <td>1</td>\n",
       "      <td>Other</td>\n",
       "      <td>Not A Brain</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patient00001_Plane1_3_of_15</td>\n",
       "      <td>1</td>\n",
       "      <td>Other</td>\n",
       "      <td>Not A Brain</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Patient00001_Plane1_4_of_15</td>\n",
       "      <td>1</td>\n",
       "      <td>Other</td>\n",
       "      <td>Not A Brain</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Patient00001_Plane1_5_of_15</td>\n",
       "      <td>1</td>\n",
       "      <td>Other</td>\n",
       "      <td>Not A Brain</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12395</th>\n",
       "      <td>Patient01791_Plane5_1_of_1</td>\n",
       "      <td>1791</td>\n",
       "      <td>Fetal femur</td>\n",
       "      <td>Not A Brain</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12396</th>\n",
       "      <td>Patient01792_Plane2_1_of_1</td>\n",
       "      <td>1792</td>\n",
       "      <td>Fetal abdomen</td>\n",
       "      <td>Not A Brain</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12397</th>\n",
       "      <td>Patient01792_Plane3_1_of_1</td>\n",
       "      <td>1792</td>\n",
       "      <td>Fetal brain</td>\n",
       "      <td>Trans-thalamic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12398</th>\n",
       "      <td>Patient01792_Plane5_1_of_1</td>\n",
       "      <td>1792</td>\n",
       "      <td>Fetal femur</td>\n",
       "      <td>Not A Brain</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12399</th>\n",
       "      <td>Patient01792_Plane6_1_of_1</td>\n",
       "      <td>1792</td>\n",
       "      <td>Fetal thorax</td>\n",
       "      <td>Not A Brain</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12400 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Image_name  Patient_num          Plane  \\\n",
       "0      Patient00001_Plane1_1_of_15            1          Other   \n",
       "1      Patient00001_Plane1_2_of_15            1          Other   \n",
       "2      Patient00001_Plane1_3_of_15            1          Other   \n",
       "3      Patient00001_Plane1_4_of_15            1          Other   \n",
       "4      Patient00001_Plane1_5_of_15            1          Other   \n",
       "...                            ...          ...            ...   \n",
       "12395   Patient01791_Plane5_1_of_1         1791    Fetal femur   \n",
       "12396   Patient01792_Plane2_1_of_1         1792  Fetal abdomen   \n",
       "12397   Patient01792_Plane3_1_of_1         1792    Fetal brain   \n",
       "12398   Patient01792_Plane5_1_of_1         1792    Fetal femur   \n",
       "12399   Patient01792_Plane6_1_of_1         1792   Fetal thorax   \n",
       "\n",
       "          Brain_plane  Train   \n",
       "0         Not A Brain       1  \n",
       "1         Not A Brain       1  \n",
       "2         Not A Brain       1  \n",
       "3         Not A Brain       1  \n",
       "4         Not A Brain       1  \n",
       "...               ...     ...  \n",
       "12395     Not A Brain       0  \n",
       "12396     Not A Brain       0  \n",
       "12397  Trans-thalamic       0  \n",
       "12398     Not A Brain       0  \n",
       "12399     Not A Brain       0  \n",
       "\n",
       "[12400 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_folder = r'C:\\Users\\Vinay Venkatachalam\\Downloads\\fetal-brain-ultrasound-deep-learning-main\\fetal-brain-ultrasound-deep-learning-main\\FETAL_PLANES_ZENODO\\02.Enhancement and Segmentation'\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the Excel file\n",
    "excel_file = r'C:\\Users\\Vinay Venkatachalam\\Downloads\\fetal-brain-ultrasound-deep-learning-main\\fetal-brain-ultrasound-deep-learning-main\\FETAL_PLANES_ZENODO\\FETAL_PLANES_DB_data.xlsx'\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel(excel_file)\n",
    "df[['Image_name'\t,'Patient_num'\t, 'Plane'\t,'Brain_plane',\t'Train ']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vivek\\AppData\\Local\\Temp\\ipykernel_2336\\3806287687.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Vivek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "PART 1 DONE\n",
      "PART 2 DONE\n",
      "PART 3 DONE\n",
      "WARNING:tensorflow:From c:\\Users\\Vivek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Vivek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Vivek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "PART 4 DONE\n",
      "Found 9920 validated image filenames belonging to 2 classes.\n",
      "Found 2480 validated image filenames belonging to 2 classes.\n",
      "PART 5 DONE\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:From c:\\Users\\Vivek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Vivek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "310/310 [==============================] - 402s 1s/step - loss: 0.5856 - accuracy: 0.6640 - val_loss: 0.5277 - val_accuracy: 0.6992\n",
      "Epoch 2/3\n",
      "310/310 [==============================] - 330s 1s/step - loss: 0.4949 - accuracy: 0.7299 - val_loss: 0.4940 - val_accuracy: 0.7274\n",
      "Epoch 3/3\n",
      "310/310 [==============================] - 358s 1s/step - loss: 0.4382 - accuracy: 0.7740 - val_loss: 0.4863 - val_accuracy: 0.7448\n",
      "PART 6 DONE\n",
      "78/78 [==============================] - 30s 389ms/step - loss: 0.4863 - accuracy: 0.7448\n",
      "Test Accuracy: 0.7447580695152283\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Load the CSV file\n",
    "data = pd.read_excel(r'C:\\Users\\Vivek\\Downloads\\FETAL_PLANES_ZENODO\\FETAL_PLANES_DB_data.xlsx')\n",
    "\n",
    "# Prepare the data\n",
    "image_dir = r'C:\\Users\\Vivek\\Downloads\\FETAL_PLANES_ZENODO\\Images'\n",
    "data['Image_path'] = data['Image_name'].apply(lambda x: os.path.join(image_dir, x + '.png'))\n",
    "print(\"PART 1 DONE\")\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['Image_path'], data['Train '], test_size=0.2, random_state=42)\n",
    "print(\"PART 2 DONE\")\n",
    "\n",
    "# Convert labels to strings\n",
    "y_train = y_train.astype(str)\n",
    "y_test = y_test.astype(str)\n",
    "\n",
    "# Initialize ImageDataGenerator for data augmentation\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "print(\"PART 3 DONE\")\n",
    "\n",
    "# Define the neural network model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(\"PART 4 DONE\")\n",
    "\n",
    "# Create data generators for training and testing\n",
    "train_generator = datagen.flow_from_dataframe(dataframe=pd.DataFrame({'Image_path': X_train, 'Train': y_train}),\n",
    "                                              x_col='Image_path', y_col='Train', target_size=(150, 150),\n",
    "                                              batch_size=32, class_mode='binary')\n",
    "test_generator = datagen.flow_from_dataframe(dataframe=pd.DataFrame({'Image_path': X_test, 'Train': y_test}),\n",
    "                                             x_col='Image_path', y_col='Train', target_size=(150, 150),\n",
    "                                             batch_size=32, class_mode='binary')\n",
    "print(\"PART 5 DONE\")\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_generator, epochs=3, validation_data=test_generator)\n",
    "print(\"PART 6 DONE\")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(test_generator)\n",
    "print(\"Test Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load the CSV file\n",
    "data = pd.read_excel(r'C:\\Users\\Vivek\\Downloads\\FETAL_PLANES_ZENODO\\FETAL_PLANES_DB_data.xlsx')\n",
    "\n",
    "# Prepare the data\n",
    "image_dir = r'C:\\Users\\Vivek\\Downloads\\FETAL_PLANES_ZENODO\\Images'\n",
    "data['Image_path'] = data['Image_name'].apply(lambda x: os.path.join(image_dir, x + '.png'))\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['Image_path'], data['Train '], test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert labels to strings\n",
    "y_train = y_train.astype(str)\n",
    "y_test = y_test.astype(str)\n",
    "\n",
    "# Initialize ImageDataGenerator for data augmentation\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Define the neural network model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Create data generators for training and testing\n",
    "train_generator = datagen.flow_from_dataframe(dataframe=pd.DataFrame({'Image_path': X_train, 'Train': y_train}),\n",
    "                                              x_col='Image_path', y_col='Train', target_size=(150, 150),\n",
    "                                              batch_size=32, class_mode='binary')\n",
    "test_generator = datagen.flow_from_dataframe(dataframe=pd.DataFrame({'Image_path': X_test, 'Train': y_test}),\n",
    "                                             x_col='Image_path', y_col='Train', target_size=(150, 150),\n",
    "                                             batch_size=32, class_mode='binary')\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_generator, epochs=3, validation_data=test_generator)\n",
    "\n",
    "# Define a function to preprocess the user's uploaded image\n",
    "def preprocess_image(image_path):\n",
    "    img = image.load_img(image_path, target_size=(150, 150))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PART 1 DONE\n",
      "PART 2 DONE\n",
      "PART 3 DONE\n",
      "PART 4 DONE\n",
      "Found 8596 validated image filenames belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vivek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\preprocessing\\image.py:1137: UserWarning: Found 1324 invalid image filename(s) in x_col=\"Image_path\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2126 validated image filenames belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vivek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\preprocessing\\image.py:1137: UserWarning: Found 354 invalid image filename(s) in x_col=\"Image_path\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PART 5 DONE\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 261s 957ms/step - loss: 0.7211 - accuracy: 0.5271 - val_loss: 0.6913 - val_accuracy: 0.5292\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 264s 982ms/step - loss: 0.6912 - accuracy: 0.5282 - val_loss: 0.6913 - val_accuracy: 0.5310\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 271s 1s/step - loss: 0.6910 - accuracy: 0.5352 - val_loss: 0.6893 - val_accuracy: 0.5329\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 264s 982ms/step - loss: 0.6901 - accuracy: 0.5339 - val_loss: 0.6890 - val_accuracy: 0.5395\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 272s 1s/step - loss: 0.6901 - accuracy: 0.5280 - val_loss: 0.6889 - val_accuracy: 0.5414\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 289s 1s/step - loss: 0.6895 - accuracy: 0.5370 - val_loss: 0.6881 - val_accuracy: 0.5353\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 285s 1s/step - loss: 0.6890 - accuracy: 0.5350 - val_loss: 0.6896 - val_accuracy: 0.5517\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 290s 1s/step - loss: 0.6893 - accuracy: 0.5369 - val_loss: 0.6907 - val_accuracy: 0.5249\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 273s 1s/step - loss: 0.6890 - accuracy: 0.5380 - val_loss: 0.6901 - val_accuracy: 0.5292\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 258s 960ms/step - loss: 0.6886 - accuracy: 0.5351 - val_loss: 0.6873 - val_accuracy: 0.5292\n",
      "PART 6 DONE\n",
      "67/67 [==============================] - 25s 368ms/step - loss: 0.6871 - accuracy: 0.5348\n",
      "Test Accuracy: 0.5348071455955505\n",
      "269/269 [==============================] - 100s 372ms/step - loss: 0.6864 - accuracy: 0.5500\n",
      "Train Accuracy: 0.5500232577323914\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Load the CSV file\n",
    "data = pd.read_excel(r'D:\\github-repos\\fetal-abnormality\\FETAL_PLANES_DB_data.xlsx')\n",
    "\n",
    "# Prepare the data\n",
    "image_dir = r'C:\\Users\\Vivek\\Downloads\\FETAL_PLANES_ZENODO\\Images\\02.Enhancement and Segmentation'\n",
    "data['Image_path'] = data['Image_name'].apply(lambda x: os.path.join(image_dir, x + '.png'))\n",
    "print(\"PART 1 DONE\")\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['Image_path'], data['Train '], test_size=0.2, random_state=42)\n",
    "print(\"PART 2 DONE\")\n",
    "\n",
    "# Convert labels to strings\n",
    "y_train = y_train.astype(str)\n",
    "y_test = y_test.astype(str)\n",
    "\n",
    "# Initialize ImageDataGenerator for data augmentation and preprocessing\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # rescale pixel values to [0,1]\n",
    "    rotation_range=20,  # rotate images randomly up to 20 degrees\n",
    "    width_shift_range=0.1,  # shift images horizontally by up to 10% of the width\n",
    "    height_shift_range=0.1,  # shift images vertically by up to 10% of the height\n",
    "    shear_range=0.1,  # shear transformation with maximum shear angle of 10%\n",
    "    zoom_range=0.1,  # zoom in or out by up to 10%\n",
    "    horizontal_flip=True,  # flip images horizontally\n",
    "    fill_mode='nearest'  # fill in newly created pixels after rotation or shifting\n",
    ")\n",
    "print(\"PART 3 DONE\")\n",
    "\n",
    "# Define the neural network model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(\"PART 4 DONE\")\n",
    "\n",
    "# Create data generators for training and testing\n",
    "train_generator = datagen.flow_from_dataframe(dataframe=pd.DataFrame({'Image_path': X_train, 'Train': y_train}),\n",
    "                                              x_col='Image_path', y_col='Train', target_size=(150, 150),\n",
    "                                              batch_size=32, class_mode='binary')\n",
    "test_generator = datagen.flow_from_dataframe(dataframe=pd.DataFrame({'Image_path': X_test, 'Train': y_test}),\n",
    "                                             x_col='Image_path', y_col='Train', target_size=(150, 150),\n",
    "                                             batch_size=32, class_mode='binary')\n",
    "print(\"PART 5 DONE\")\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_generator, epochs=10, validation_data=test_generator)\n",
    "print(\"PART 6 DONE\")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(test_generator)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "loss, accuracy = model.evaluate(train_generator)\n",
    "print(\"Train Accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Vivek\\\\Downloads\\\\FETAL_PLANES_ZENODO\\\\Images\\\\Patient01694_Plane6_1_of_1.png'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[11809]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2316     1\n",
       "1121     1\n",
       "4560     1\n",
       "11809    0\n",
       "8664     0\n",
       "        ..\n",
       "1180     1\n",
       "6152     1\n",
       "1911     1\n",
       "8704     0\n",
       "8022     0\n",
       "Name: Train , Length: 2480, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO save the model for future use:\n",
    "# model.save('fetal_brain_model.h5')\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vivek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# TO save the model for future use:\n",
    "model.save('fetal_brain_model_two.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Vivek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Vivek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Vivek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To load the saved model later for predicting:\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the model\n",
    "loaded_model = load_model('fetal_brain_model_two.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Patient01792_Plane2_1_of_1.png'] Patient01792_Plane2_1_of_1.png\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Predicted Class: 0\n",
      "Unhealthy\n"
     ]
    }
   ],
   "source": [
    "# To Test another image:\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# function to preprocess the image\n",
    "def preprocess_image(image_path):\n",
    "    img = image.load_img(image_path, target_size=(150, 150))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    return img_array\n",
    "\n",
    "files = os.listdir('uploads')\n",
    "print(files, files[0])\n",
    "\n",
    "path_of_image = rf'uploads\\{files[0]}'\n",
    "# Path to the image you want to test\n",
    "test_image_path = path_of_image\n",
    "\n",
    "# Preprocess the image\n",
    "processed_image = preprocess_image(test_image_path)\n",
    "\n",
    "# Make predictions\n",
    "prediction = loaded_model.predict(processed_image)\n",
    "\n",
    "# Convert the prediction to 0 or 1\n",
    "prediction_class = 1 if prediction > 0.5 else 0\n",
    "\n",
    "print(\"Predicted Class:\", prediction_class)\n",
    "if prediction_class == 0:\n",
    "    print(\"Unhealthy\")\n",
    "else:\n",
    "    print(\"Healthy\")\n",
    "os.remove(path_of_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[df['Brain_plane'] != \"NOT A BRAIN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 29s 370ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = loaded_model.predict(test_generator)\n",
    "y_pred_classes = (y_pred > 0.5).astype(\"int32\")\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(test_generator.classes, y_pred_classes)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "            xticklabels=train_generator.class_indices, \n",
    "            yticklabels=train_generator.class_indices)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      " * Restarting with stat\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      " * Restarting with stat\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
